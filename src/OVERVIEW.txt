The 'models' folder contains the trained logistic regression file (logreg_compelte.pkl) and
the corresponding labels file (keypoint_classifier_label.csv).

The 'notebooks' folder contains the Jupyter notebook (logreg.ipynb) used to train our logistic classifier.

The 'songs' folder contains the .mp3 files our speaker can play.

The 'utils' folder contains a few scripts used in other programs.

data_collection.py is used to collect the 21 keypoints associated with a gesture.
It is used to collect data so that new classifiers can be trained.
It requires a camera to run and is to be used on a laptop.

debug_gesture_detection.py is used to see if the gesture classifiers are correctly working.
It requires a camera to run and is to be used on a laptop.

gesture_detection.py runs on an RPI.
The script collects gesture data to be transmitted to another RPI.

speaker_led_control.py runs on an RPI.
The script receives gesture data from another RPI and changes the speaker and LED settings accordingly.