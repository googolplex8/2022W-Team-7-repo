The 'models' folder contains the trained SVM model (svm.pkl), logistic regression model (logreg_complete.pkl) and the corresponding labels file (keypoint_classifier_label.csv).

The 'notebooks' folder contains the Jupyter notebook used to train our classifiers(Classifier Comparison.ipynb), and the notebook used to test preprocessing methods (Preprocessing.ipynb).

The 'songs' folder contains the .mp3 files our speaker can play.

The 'utils' folder contains a few scripts used in other programs.

data_collection.py is used to collect the 21 keypoints associated with a gesture.
It is used to collect data so that new classifiers can be trained.
It requires a camera to run and is to be used on a laptop.

debug_gesture_detection.py is used to see if the gesture classifiers are correctly working.
It requires a camera to run and is to be used on a laptop.

gesture_detection.py runs on an RPI.
The script collects gesture data to be transmitted to another RPI.

speaker_led_control.py runs on an RPI.
The script receives gesture data from another RPI and changes the speaker and LED settings accordingly.
